{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from  sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import PolynomialFeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = pd.read_csv('E:\\\\Dev\\\\AV\\\\train_votes.csv')\n",
    "train = train.drop(train[train.Views > 3000000].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder_X = LabelEncoder()\n",
    "train['Tag'] = labelencoder_X.fit_transform(train['Tag'])\n",
    "train.drop(['ID','Username'], axis=1,inplace =True)\n",
    "target = train['Upvotes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "bn = Binarizer(threshold=7)\n",
    "pd_watched = bn.transform([train['Answers']])[0]\n",
    "train['pd_watched'] = pd_watched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [x for x in train.columns if x not in ['Upvotes']]\n",
    "x_train, x_test, y_train, y_test = train_test_split(train[feature_names], target,test_size = 0.22,random_state =205)\n",
    "sc_X = StandardScaler()\n",
    "x_train = sc_X.fit_transform(x_train)\n",
    "x_test = sc_X.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = sc_X.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error : 168.01354142729278\n",
      "R2 Score : 0.8534901497156416\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "my_model = XGBRegressor()\n",
    "# Add silent=True to avoid printing out updates with each cycle\n",
    "my_model.fit(x_train, y_train, verbose=False)\n",
    "# make predictions\n",
    "predictions = my_model.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print(\"Mean Absolute Error : \" + str(mean_absolute_error( y_test,predictions)))\n",
    "print(\"R2 Score : \" + str(r2_score(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error : 168.01354142729278\n",
      "R2 Score : 0.8534901497156416\n"
     ]
    }
   ],
   "source": [
    "my_model = XGBRegressor(n_estimators=1000, learning_rate=0.05)\n",
    "\n",
    "my_model.fit(x_train, y_train, early_stopping_rounds=20, \n",
    "             eval_set=[(x_test, y_test)], verbose=False)\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "    \n",
    "print(\"Mean Absolute Error : \" + str(mean_absolute_error(predictions, y_test)))\n",
    "print(\"R2 Score : \" + str(r2_score(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8534901497156416\n"
     ]
    }
   ],
   "source": [
    "print(r2_score(y_test, predictions))\n",
    "# testing\n",
    "test = pd.read_csv('E:\\\\Dev\\\\AV\\\\test_votes.csv')\n",
    "ids = test['ID']\n",
    "test.drop(['ID','Username'], axis=1,inplace =True)\n",
    "#25-March - 0.903437879332785\n",
    "#next 0.9034534322501852\n",
    "#0.9037949838052866 - lb .794 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder_X = LabelEncoder()\n",
    "test['Tag'] = labelencoder_X.fit_transform(test['Tag'])\n",
    "from sklearn.preprocessing import Binarizer\n",
    "bn = Binarizer(threshold=7)\n",
    "pd_watched = bn.transform([test['Answers']])[0]\n",
    "test['pd_watched'] = pd_watched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = sc_X.fit_transform(test)\n",
    "pred_test = my_model.predict(test)\n",
    "pred_test=abs(pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "submission = pd.DataFrame({'ID': ids,\n",
    "                           'Upvotes':pred_test\n",
    "                           })\n",
    "\n",
    "submission.to_csv(\"submit_\" +str( datetime.date.today())+ \"_nr.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.9034534322501852 - 0.903437879332785 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.linear_model.coordinate_descent import Lasso, \\\n",
    "    LassoCV, ElasticNet, ElasticNetCV, MultiTaskLasso, MultiTaskElasticNet, \\\n",
    "    MultiTaskElasticNetCV, MultiTaskLassoCV, lasso_path, enet_path\n",
    "from sklearn.linear_model.coordinate_descent import Lasso, \\\n",
    "    LassoCV\n",
    "from sklearn.linear_model import LassoLarsCV, lars_path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size = 0.2, random_state = 0)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(train[feature_names], target, test_size = 0.22,random_state =205)\n",
    "def test_lasso_cv():\n",
    "    #X_train, y_train, X_test, y_test = build_dataset()\n",
    "    X_train, y_train, X_test, y_test = train_test_split(train[feature_names], target, test_size = 0.22,random_state =205)\n",
    "    clf = LassoCV(n_alphas=10, eps=1e-3, max_iter=150, precompute=True)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Check that the lars and the coordinate descent implementation\n",
    "    # select a similar alpha\n",
    "    lars = LassoLarsCV(normalize=False, max_iter=30).fit(X_train, y_train)\n",
    "\n",
    "    #mse_lars = interpolate.interp1d(lars.cv_alphas_, lars.mse_path_.T)\n",
    "    # test set\n",
    "    print(clf.score(X_test, y_test))\n",
    "    print(lars.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(n_samples=50, n_features=200, n_informative_features=10,\n",
    "                  n_targets=1):\n",
    "    \"\"\"\n",
    "    build an ill-posed linear regression problem with many noisy features and\n",
    "    comparatively few samples\n",
    "    \"\"\"\n",
    "    random_state = np.random.RandomState(0)\n",
    "    if n_targets > 1:\n",
    "        w = random_state.randn(n_features, n_targets)\n",
    "    else:\n",
    "        w = random_state.randn(n_features)\n",
    "    w[n_informative_features:] = 0.0\n",
    "    X = random_state.randn(n_samples, n_features)\n",
    "    y = np.dot(X, w)\n",
    "    X_test = random_state.randn(n_samples, n_features)\n",
    "    y_test = np.dot(X_test, w)\n",
    "    return X, y, X_test, y_test\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lasso_cv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
